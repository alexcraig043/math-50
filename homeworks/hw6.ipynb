{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M50 Homework 6\n",
    "\n",
    "## Alex Craig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "(Car brands and mpg): In this exercise we will consider the data set containing information about cars and their miles per gallon. This can by loaded by\n",
    "\n",
    "```python\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/intro-stat-learning/ISLP/main/ISLP/data/Auto.csv\",encoding = \"ISO-8859-1\")\n",
    "\n",
    "data[\"name\"] = [name.split()[0] for name in data[\"name\"].values]\n",
    "```\n",
    "\n",
    "The second line takes the original names (which are the specific models – e.g. Toyota Yaris) and extracts only the brand name (e.g Toyota). We are going to study which brands have the best mpg. Some brands tend to make larger and heavier cars (e.g. pickup tricks) which will have worse mpg, but we want to understand how brands compare within a certain type of car. To determine this we need to control for other factors, such as the the year and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Using all the columns **except** origin and displacement (since it’s not obvious what the units are), write down the regression model which you want to fit to this data to address the question posed in the problem instruction. Assume there are no interactions. Provide an interpretation of each regression coefficient.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year   \n",
       "0  18.0          8         307.0         130    3504          12.0    70  \\\n",
       "1  15.0          8         350.0         165    3693          11.5    70   \n",
       "2  18.0          8         318.0         150    3436          11.0    70   \n",
       "3  16.0          8         304.0         150    3433          12.0    70   \n",
       "4  17.0          8         302.0         140    3449          10.5    70   \n",
       "\n",
       "   origin       name  \n",
       "0       1  chevrolet  \n",
       "1       1      buick  \n",
       "2       1   plymouth  \n",
       "3       1        amc  \n",
       "4       1       ford  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/intro-stat-learning/ISLP/main/ISLP/data/Auto.csv\",encoding = \"ISO-8859-1\")\n",
    "\n",
    "data[\"name\"] = [name.split()[0] for name in data[\"name\"].values]\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression model is:\n",
    "\n",
    "$$\n",
    "\\text{mpg} = \\beta_0 + \\beta_1 \\times \\text{name} + \\beta_2 \\times \\text{cylinders} + \\beta_3 \\times \\text{horsepower} \n",
    "$$\n",
    "$$\n",
    "+ \\beta_4 \\times \\text{weight} + \\beta_5 \\times \\text{acceleration} + \\beta_6 \\times \\text{year} + \\epsilon\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\text{mpg}$ is the response variable representing the miles per gallon.\n",
    "- $\\text{name}$ is a categorical variable representing the brand of the car. In the regression model, this will be translated to several dummy variables (one for each brand).\n",
    "- $\\text{cylinders}$ represents the number of cylinders in the car's engine.\n",
    "- $\\text{horsepower}$ represents the horsepower of the car.\n",
    "- $\\text{weight}$ represents the weight of the car.\n",
    "- $\\text{acceleration}$ represents the acceleration of the car.\n",
    "- $\\text{year}$ represents the year the car was made.\n",
    "- $\\epsilon$ is the error term.\n",
    "\n",
    "Interpretation of the coefficients:\n",
    "- $\\beta_0$: This is the intercept. It represents the expected mpg when all other predictors are zero. However, in this context, a value of zero for many predictors doesn't make sense (e.g., a car weight of zero), so the intercept might be more of a mathematical convenience rather than having a direct interpretative meaning.\n",
    "- $\\beta_1$: Represents the difference in mpg for a given brand, holding all other predictors constant.\n",
    "- $\\beta_2$: Represents the change in mpg for a one-unit increase in the number of cylinders, holding all other predictors constant.\n",
    "- $\\beta_3$: Represents the change in mpg for a one-unit increase in horsepower, holding all other predictors constant.\n",
    "- $\\beta_4$: Represents the change in mpg for a one-unit increase in weight, holding all other predictors constant.\n",
    "- $\\beta_5$: Represents the change in mpg for a one-unit increase in acceleration, holding all other predictors constant.\n",
    "- $\\beta_6$: Represents the change in mpg for a one-year increase in the year the car was made, holding all other predictors constant.\n",
    "\n",
    "Note: The categorical variable `name` will result in multiple coefficients, one for each level (brand) of the variable, minus one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "Fit the regression model to the data.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We first need to clean the data. There are certain brand names that have been misspelled or written in different ways. We'll standardize these brand names to have consistent naming.\n",
    "2. We will then create dummy variables for the 'name' column which represents the brand names. This is essential because 'name' is a categorical variable, and we need to convert it into a format that can be used in regression analysis.\n",
    "3. We will drop the columns 'origin' and 'displacement' as instructed.\n",
    "4. Next, we'll define our predictors and the response variable. Our predictors will be all columns except for 'mpg', and our response will be 'mpg'.\n",
    "5. We'll add a constant to our predictors. This constant acts as the intercept in the regression equation.\n",
    "6. Finally, we'll fit our regression model using the OLS (Ordinary Least Squares) method and get a summary of the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.839</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.823</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   51.41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 02 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>8.82e-119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:13:44</td>     <th>  Log-Likelihood:    </th> <td> -1003.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2080.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   355</td>      <th>  BIC:               </th> <td>   2227.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    36</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>  -13.1962</td> <td>    4.915</td> <td>   -2.685</td> <td> 0.008</td> <td>  -22.863</td> <td>   -3.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cylinders</th>       <td>    0.0152</td> <td>    0.270</td> <td>    0.056</td> <td> 0.955</td> <td>   -0.516</td> <td>    0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>      <td>   -0.0112</td> <td>    0.014</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.039</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>          <td>   -0.0054</td> <td>    0.001</td> <td>   -8.459</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th>    <td>    0.0122</td> <td>    0.106</td> <td>    0.115</td> <td> 0.908</td> <td>   -0.196</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>            <td>    0.7174</td> <td>    0.055</td> <td>   13.147</td> <td> 0.000</td> <td>    0.610</td> <td>    0.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_amc</th>        <td>   -2.9815</td> <td>    0.719</td> <td>   -4.145</td> <td> 0.000</td> <td>   -4.396</td> <td>   -1.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_audi</th>       <td>    0.1644</td> <td>    1.244</td> <td>    0.132</td> <td> 0.895</td> <td>   -2.282</td> <td>    2.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_bmw</th>        <td>   -1.6429</td> <td>    2.296</td> <td>   -0.716</td> <td> 0.475</td> <td>   -6.158</td> <td>    2.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_buick</th>      <td>   -1.7121</td> <td>    0.889</td> <td>   -1.925</td> <td> 0.055</td> <td>   -3.461</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_cadillac</th>   <td>    1.2003</td> <td>    2.337</td> <td>    0.514</td> <td> 0.608</td> <td>   -3.397</td> <td>    5.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_capri</th>      <td>   -1.5925</td> <td>    3.205</td> <td>   -0.497</td> <td> 0.620</td> <td>   -7.895</td> <td>    4.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_chevrolet</th>  <td>   -1.7765</td> <td>    0.604</td> <td>   -2.940</td> <td> 0.003</td> <td>   -2.965</td> <td>   -0.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_chevy</th>      <td>   -1.8690</td> <td>    1.907</td> <td>   -0.980</td> <td> 0.328</td> <td>   -5.618</td> <td>    1.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_chrysler</th>   <td>   -2.3533</td> <td>    1.405</td> <td>   -1.674</td> <td> 0.095</td> <td>   -5.117</td> <td>    0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_datsun</th>     <td>    1.9952</td> <td>    0.767</td> <td>    2.602</td> <td> 0.010</td> <td>    0.487</td> <td>    3.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_dodge</th>      <td>   -1.2208</td> <td>    0.709</td> <td>   -1.723</td> <td> 0.086</td> <td>   -2.614</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_fiat</th>       <td>    1.0326</td> <td>    1.181</td> <td>    0.874</td> <td> 0.383</td> <td>   -1.291</td> <td>    3.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_ford</th>       <td>   -2.3973</td> <td>    0.591</td> <td>   -4.056</td> <td> 0.000</td> <td>   -3.560</td> <td>   -1.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_hi</th>         <td>   -0.5520</td> <td>    3.341</td> <td>   -0.165</td> <td> 0.869</td> <td>   -7.123</td> <td>    6.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_honda</th>      <td>    1.8142</td> <td>    0.984</td> <td>    1.844</td> <td> 0.066</td> <td>   -0.121</td> <td>    3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_maxda</th>      <td>   -3.5229</td> <td>    2.288</td> <td>   -1.540</td> <td> 0.124</td> <td>   -8.022</td> <td>    0.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_mazda</th>      <td>    0.1005</td> <td>    1.088</td> <td>    0.092</td> <td> 0.926</td> <td>   -2.040</td> <td>    2.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_mercedes</th>   <td>    0.7943</td> <td>    1.935</td> <td>    0.411</td> <td> 0.682</td> <td>   -3.011</td> <td>    4.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_mercury</th>    <td>   -2.6242</td> <td>    1.044</td> <td>   -2.513</td> <td> 0.012</td> <td>   -4.678</td> <td>   -0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_nissan</th>     <td>    2.8302</td> <td>    3.234</td> <td>    0.875</td> <td> 0.382</td> <td>   -3.530</td> <td>    9.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_oldsmobile</th> <td>   -0.6376</td> <td>    1.143</td> <td>   -0.558</td> <td> 0.577</td> <td>   -2.885</td> <td>    1.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_opel</th>       <td>   -1.1915</td> <td>    1.631</td> <td>   -0.731</td> <td> 0.465</td> <td>   -4.398</td> <td>    2.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_peugeot</th>    <td>   -0.3003</td> <td>    1.227</td> <td>   -0.245</td> <td> 0.807</td> <td>   -2.713</td> <td>    2.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_plymouth</th>   <td>   -0.5465</td> <td>    0.668</td> <td>   -0.818</td> <td> 0.414</td> <td>   -1.861</td> <td>    0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_pontiac</th>    <td>    0.1306</td> <td>    0.897</td> <td>    0.145</td> <td> 0.884</td> <td>   -1.634</td> <td>    1.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_renault</th>    <td>    0.8053</td> <td>    1.878</td> <td>    0.429</td> <td> 0.668</td> <td>   -2.887</td> <td>    4.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_saab</th>       <td>   -0.7845</td> <td>    1.646</td> <td>   -0.477</td> <td> 0.634</td> <td>   -4.021</td> <td>    2.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_subaru</th>     <td>   -0.0408</td> <td>    1.641</td> <td>   -0.025</td> <td> 0.980</td> <td>   -3.268</td> <td>    3.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_toyota</th>     <td>   -0.2083</td> <td>    0.714</td> <td>   -0.292</td> <td> 0.771</td> <td>   -1.612</td> <td>    1.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_triumph</th>    <td>    5.1005</td> <td>    3.216</td> <td>    1.586</td> <td> 0.114</td> <td>   -1.223</td> <td>   11.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_volkswagen</th> <td>    1.5314</td> <td>    0.785</td> <td>    1.950</td> <td> 0.052</td> <td>   -0.013</td> <td>    3.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name_volvo</th>      <td>   -2.7411</td> <td>    1.350</td> <td>   -2.031</td> <td> 0.043</td> <td>   -5.395</td> <td>   -0.087</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>33.939</td> <th>  Durbin-Watson:     </th> <td>   1.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  53.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.575</td> <th>  Prob(JB):          </th> <td>1.89e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.409</td> <th>  Cond. No.          </th> <td>2.50e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.01e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.839   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.823   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     51.41   \\\\\n",
       "\\textbf{Date:}             & Thu, 02 Nov 2023 & \\textbf{  Prob (F-statistic):} & 8.82e-119   \\\\\n",
       "\\textbf{Time:}             &     13:13:44     & \\textbf{  Log-Likelihood:    } &   -1003.2   \\\\\n",
       "\\textbf{No. Observations:} &         392      & \\textbf{  AIC:               } &     2080.   \\\\\n",
       "\\textbf{Df Residuals:}     &         355      & \\textbf{  BIC:               } &     2227.   \\\\\n",
       "\\textbf{Df Model:}         &          36      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}            &     -13.1962  &        4.915     &    -2.685  &         0.008        &      -22.863    &       -3.530     \\\\\n",
       "\\textbf{cylinders}        &       0.0152  &        0.270     &     0.056  &         0.955        &       -0.516    &        0.546     \\\\\n",
       "\\textbf{horsepower}       &      -0.0112  &        0.014     &    -0.786  &         0.432        &       -0.039    &        0.017     \\\\\n",
       "\\textbf{weight}           &      -0.0054  &        0.001     &    -8.459  &         0.000        &       -0.007    &       -0.004     \\\\\n",
       "\\textbf{acceleration}     &       0.0122  &        0.106     &     0.115  &         0.908        &       -0.196    &        0.221     \\\\\n",
       "\\textbf{year}             &       0.7174  &        0.055     &    13.147  &         0.000        &        0.610    &        0.825     \\\\\n",
       "\\textbf{name\\_amc}        &      -2.9815  &        0.719     &    -4.145  &         0.000        &       -4.396    &       -1.567     \\\\\n",
       "\\textbf{name\\_audi}       &       0.1644  &        1.244     &     0.132  &         0.895        &       -2.282    &        2.611     \\\\\n",
       "\\textbf{name\\_bmw}        &      -1.6429  &        2.296     &    -0.716  &         0.475        &       -6.158    &        2.872     \\\\\n",
       "\\textbf{name\\_buick}      &      -1.7121  &        0.889     &    -1.925  &         0.055        &       -3.461    &        0.037     \\\\\n",
       "\\textbf{name\\_cadillac}   &       1.2003  &        2.337     &     0.514  &         0.608        &       -3.397    &        5.797     \\\\\n",
       "\\textbf{name\\_capri}      &      -1.5925  &        3.205     &    -0.497  &         0.620        &       -7.895    &        4.710     \\\\\n",
       "\\textbf{name\\_chevrolet}  &      -1.7765  &        0.604     &    -2.940  &         0.003        &       -2.965    &       -0.588     \\\\\n",
       "\\textbf{name\\_chevy}      &      -1.8690  &        1.907     &    -0.980  &         0.328        &       -5.618    &        1.881     \\\\\n",
       "\\textbf{name\\_chrysler}   &      -2.3533  &        1.405     &    -1.674  &         0.095        &       -5.117    &        0.411     \\\\\n",
       "\\textbf{name\\_datsun}     &       1.9952  &        0.767     &     2.602  &         0.010        &        0.487    &        3.503     \\\\\n",
       "\\textbf{name\\_dodge}      &      -1.2208  &        0.709     &    -1.723  &         0.086        &       -2.614    &        0.173     \\\\\n",
       "\\textbf{name\\_fiat}       &       1.0326  &        1.181     &     0.874  &         0.383        &       -1.291    &        3.356     \\\\\n",
       "\\textbf{name\\_ford}       &      -2.3973  &        0.591     &    -4.056  &         0.000        &       -3.560    &       -1.235     \\\\\n",
       "\\textbf{name\\_hi}         &      -0.5520  &        3.341     &    -0.165  &         0.869        &       -7.123    &        6.019     \\\\\n",
       "\\textbf{name\\_honda}      &       1.8142  &        0.984     &     1.844  &         0.066        &       -0.121    &        3.749     \\\\\n",
       "\\textbf{name\\_maxda}      &      -3.5229  &        2.288     &    -1.540  &         0.124        &       -8.022    &        0.977     \\\\\n",
       "\\textbf{name\\_mazda}      &       0.1005  &        1.088     &     0.092  &         0.926        &       -2.040    &        2.241     \\\\\n",
       "\\textbf{name\\_mercedes}   &       0.7943  &        1.935     &     0.411  &         0.682        &       -3.011    &        4.600     \\\\\n",
       "\\textbf{name\\_mercury}    &      -2.6242  &        1.044     &    -2.513  &         0.012        &       -4.678    &       -0.571     \\\\\n",
       "\\textbf{name\\_nissan}     &       2.8302  &        3.234     &     0.875  &         0.382        &       -3.530    &        9.191     \\\\\n",
       "\\textbf{name\\_oldsmobile} &      -0.6376  &        1.143     &    -0.558  &         0.577        &       -2.885    &        1.609     \\\\\n",
       "\\textbf{name\\_opel}       &      -1.1915  &        1.631     &    -0.731  &         0.465        &       -4.398    &        2.015     \\\\\n",
       "\\textbf{name\\_peugeot}    &      -0.3003  &        1.227     &    -0.245  &         0.807        &       -2.713    &        2.113     \\\\\n",
       "\\textbf{name\\_plymouth}   &      -0.5465  &        0.668     &    -0.818  &         0.414        &       -1.861    &        0.767     \\\\\n",
       "\\textbf{name\\_pontiac}    &       0.1306  &        0.897     &     0.145  &         0.884        &       -1.634    &        1.896     \\\\\n",
       "\\textbf{name\\_renault}    &       0.8053  &        1.878     &     0.429  &         0.668        &       -2.887    &        4.498     \\\\\n",
       "\\textbf{name\\_saab}       &      -0.7845  &        1.646     &    -0.477  &         0.634        &       -4.021    &        2.452     \\\\\n",
       "\\textbf{name\\_subaru}     &      -0.0408  &        1.641     &    -0.025  &         0.980        &       -3.268    &        3.186     \\\\\n",
       "\\textbf{name\\_toyota}     &      -0.2083  &        0.714     &    -0.292  &         0.771        &       -1.612    &        1.196     \\\\\n",
       "\\textbf{name\\_triumph}    &       5.1005  &        3.216     &     1.586  &         0.114        &       -1.223    &       11.424     \\\\\n",
       "\\textbf{name\\_volkswagen} &       1.5314  &        0.785     &     1.950  &         0.052        &       -0.013    &        3.076     \\\\\n",
       "\\textbf{name\\_volvo}      &      -2.7411  &        1.350     &    -2.031  &         0.043        &       -5.395    &       -0.087     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 33.939 & \\textbf{  Durbin-Watson:     } &    1.209  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   53.994  \\\\\n",
       "\\textbf{Skew:}          &  0.575 & \\textbf{  Prob(JB):          } & 1.89e-12  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.409 & \\textbf{  Cond. No.          } & 2.50e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 6.01e-24. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.839\n",
       "Model:                            OLS   Adj. R-squared:                  0.823\n",
       "Method:                 Least Squares   F-statistic:                     51.41\n",
       "Date:                Thu, 02 Nov 2023   Prob (F-statistic):          8.82e-119\n",
       "Time:                        13:13:44   Log-Likelihood:                -1003.2\n",
       "No. Observations:                 392   AIC:                             2080.\n",
       "Df Residuals:                     355   BIC:                             2227.\n",
       "Df Model:                          36                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const             -13.1962      4.915     -2.685      0.008     -22.863      -3.530\n",
       "cylinders           0.0152      0.270      0.056      0.955      -0.516       0.546\n",
       "horsepower         -0.0112      0.014     -0.786      0.432      -0.039       0.017\n",
       "weight             -0.0054      0.001     -8.459      0.000      -0.007      -0.004\n",
       "acceleration        0.0122      0.106      0.115      0.908      -0.196       0.221\n",
       "year                0.7174      0.055     13.147      0.000       0.610       0.825\n",
       "name_amc           -2.9815      0.719     -4.145      0.000      -4.396      -1.567\n",
       "name_audi           0.1644      1.244      0.132      0.895      -2.282       2.611\n",
       "name_bmw           -1.6429      2.296     -0.716      0.475      -6.158       2.872\n",
       "name_buick         -1.7121      0.889     -1.925      0.055      -3.461       0.037\n",
       "name_cadillac       1.2003      2.337      0.514      0.608      -3.397       5.797\n",
       "name_capri         -1.5925      3.205     -0.497      0.620      -7.895       4.710\n",
       "name_chevrolet     -1.7765      0.604     -2.940      0.003      -2.965      -0.588\n",
       "name_chevy         -1.8690      1.907     -0.980      0.328      -5.618       1.881\n",
       "name_chrysler      -2.3533      1.405     -1.674      0.095      -5.117       0.411\n",
       "name_datsun         1.9952      0.767      2.602      0.010       0.487       3.503\n",
       "name_dodge         -1.2208      0.709     -1.723      0.086      -2.614       0.173\n",
       "name_fiat           1.0326      1.181      0.874      0.383      -1.291       3.356\n",
       "name_ford          -2.3973      0.591     -4.056      0.000      -3.560      -1.235\n",
       "name_hi            -0.5520      3.341     -0.165      0.869      -7.123       6.019\n",
       "name_honda          1.8142      0.984      1.844      0.066      -0.121       3.749\n",
       "name_maxda         -3.5229      2.288     -1.540      0.124      -8.022       0.977\n",
       "name_mazda          0.1005      1.088      0.092      0.926      -2.040       2.241\n",
       "name_mercedes       0.7943      1.935      0.411      0.682      -3.011       4.600\n",
       "name_mercury       -2.6242      1.044     -2.513      0.012      -4.678      -0.571\n",
       "name_nissan         2.8302      3.234      0.875      0.382      -3.530       9.191\n",
       "name_oldsmobile    -0.6376      1.143     -0.558      0.577      -2.885       1.609\n",
       "name_opel          -1.1915      1.631     -0.731      0.465      -4.398       2.015\n",
       "name_peugeot       -0.3003      1.227     -0.245      0.807      -2.713       2.113\n",
       "name_plymouth      -0.5465      0.668     -0.818      0.414      -1.861       0.767\n",
       "name_pontiac        0.1306      0.897      0.145      0.884      -1.634       1.896\n",
       "name_renault        0.8053      1.878      0.429      0.668      -2.887       4.498\n",
       "name_saab          -0.7845      1.646     -0.477      0.634      -4.021       2.452\n",
       "name_subaru        -0.0408      1.641     -0.025      0.980      -3.268       3.186\n",
       "name_toyota        -0.2083      0.714     -0.292      0.771      -1.612       1.196\n",
       "name_triumph        5.1005      3.216      1.586      0.114      -1.223      11.424\n",
       "name_volkswagen     1.5314      0.785      1.950      0.052      -0.013       3.076\n",
       "name_volvo         -2.7411      1.350     -2.031      0.043      -5.395      -0.087\n",
       "==============================================================================\n",
       "Omnibus:                       33.939   Durbin-Watson:                   1.209\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.994\n",
       "Skew:                           0.575   Prob(JB):                     1.89e-12\n",
       "Kurtosis:                       4.409   Cond. No.                     2.50e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.01e-24. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "data['name'] = data['name'].replace(['vw'], 'volkswagen')\n",
    "data['name'] = data['name'].replace(['vokswagen'], 'volkswagen')\n",
    "data['name'] = data['name'].replace(['chevroelt'], 'chevrolet')\n",
    "data['name'] = data['name'].replace(['toyouta'], 'toyota')\n",
    "data['name'] = data['name'].replace(['mercedes-benz'], 'mercedes')\n",
    "\n",
    "# Create dummy variables for the 'name' column\n",
    "data_dummies = pd.get_dummies(data['name'], prefix='name')\n",
    "\n",
    "# Add dummy variables to the main data and drop the original 'name' column\n",
    "data = pd.concat([data, data_dummies], axis=1).drop('name', axis=1)\n",
    "\n",
    "# Drop the columns 'origin' and 'displacement' as instructed\n",
    "data = data.drop(['origin', 'displacement'], axis=1)\n",
    "\n",
    "# Convert all entries that are \"True\" to 1 and all entries that are \"False\" to 0\n",
    "data = data * 1\n",
    "\n",
    "# Define the predictors and the response variable\n",
    "X = data.drop('mpg', axis=1)\n",
    "y = data['mpg']\n",
    "\n",
    "# Add an intercept to the predictors\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the summary of the regression model\n",
    "model_summary = model.summary()\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "What are the 5 best brands for mpg within the same type of car (weight, horsepower etc.).\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_triumph       5.100500\n",
      "name_nissan        2.830246\n",
      "name_datsun        1.995171\n",
      "name_honda         1.814166\n",
      "name_volkswagen    1.531434\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficients\n",
    "coefficients = model.params\n",
    "\n",
    "# Filter out coefficients corresponding to the car brands\n",
    "brand_coefficients = coefficients.filter(like='name_')\n",
    "\n",
    "# Sort the coefficients in descending order\n",
    "sorted_brands = brand_coefficients.sort_values(ascending=False)\n",
    "\n",
    "# Get the top 5 brands\n",
    "top_5_brands = sorted_brands.head(5)\n",
    "\n",
    "print(top_5_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the top 5 brands for mpg are:\n",
    "1. Triumph\n",
    "2. Nissan\n",
    "3. Datsun\n",
    "4. Honda\n",
    "5. Volkswagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "(Marginal regression in interactions model): Consider the probability model:\n",
    "\n",
    "$$\n",
    "X_1 \\sim N(0, \\sigma_1^2)\n",
    "$$\n",
    "$$\n",
    "X_2 \\sim N(0, \\sigma_2^2)\n",
    "$$\n",
    "$$\n",
    "Y \\mid (X_1, X_2) \\sim N(\\beta_1 X_1 + \\beta_2 X_2 + \\beta_{1,2} X_1 X_2, \\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Derive the distributions of $Y \\mid X_1$ and $Y \\mid X_2$. Hint: These conditional distributions are both normal, so you only need to determine the mean and variance to find the distributions.\n",
    "\n",
    "### Solution\n",
    "To derive the distributions of $Y \\mid X_1$ and $Y \\mid X_2$, we'll proceed in two steps:\n",
    "\n",
    "1. Compute the mean of the conditional distribution.\n",
    "2. Compute the variance of the conditional distribution.\n",
    "\n",
    "### Distribution of $Y \\mid X_1$\n",
    "\n",
    "Given $X_1 = x_1$:\n",
    "\n",
    "#### Mean:\n",
    "$$\n",
    "E[Y \\mid X_1 = x_1] = E[\\beta_1 x_1 + \\beta_2 X_2 + \\beta_{1,2} x_1 X_2]\n",
    "$$\n",
    "\n",
    "Using the linearity of expectation and knowing that $E[X_2] = 0$ (since $X_2 \\sim N(0, \\sigma_2^2)$), we have:\n",
    "\n",
    "$$\n",
    "E[Y \\mid X_1 = x_1] = \\beta_1 x_1 + \\beta_2 E[X_2] + \\beta_{1,2} x_1 E[X_2] = \\beta_1 x_1\n",
    "$$\n",
    "\n",
    "#### Variance:\n",
    "$$\n",
    "\\text{Var}(Y \\mid X_1 = x_1) = \\text{Var}(\\beta_1 x_1 + \\beta_2 X_2 + \\beta_{1,2} x_1 X_2)\n",
    "$$\n",
    "\n",
    "Using properties of variance, we get:\n",
    "\n",
    "$$\n",
    "\\text{Var}(Y \\mid X_1 = x_1) = \\beta_2^2 \\text{Var}(X_2) + \\beta_{1,2}^2 x_1^2 \\text{Var}(X_2) + \\sigma^2\n",
    "$$\n",
    "\n",
    "The $\\sigma^2$ term comes from the fact that $X_2$ and $X_1$ are not independent, so we need to add the covariance term.\n",
    "\n",
    "Given $\\text{Var}(X_2) = \\sigma_2^2$, we have:\n",
    "\n",
    "$$\n",
    "\\text{Var}(Y \\mid X_1 = x_1) = \\beta_2^2 \\sigma_2^2 + \\beta_{1,2}^2 x_1^2 \\sigma_2^2 + \\sigma^2\n",
    "$$\n",
    "\n",
    "Thus, the conditional distribution $Y \\mid X_1$ is:\n",
    "$$\n",
    "Y \\mid X_1 \\sim N(\\beta_1 x_1, \\beta_2^2 \\sigma_2^2 + \\beta_{1,2}^2 x_1^2 \\sigma_2^2 + \\sigma^2)\n",
    "$$\n",
    "\n",
    "### Distribution of $Y \\mid X_2$\n",
    "\n",
    "Given $X_2 = x_2$:\n",
    "\n",
    "#### Mean:\n",
    "$$\n",
    "E[Y \\mid X_2 = x_2] = E[\\beta_1 X_1 + \\beta_2 x_2 + \\beta_{1,2} X_1 x_2]\n",
    "$$\n",
    "\n",
    "Using the linearity of expectation and knowing that $E[X_1] = 0$ (since $X_1 \\sim N(0, \\sigma_1^2)$), we have:\n",
    "\n",
    "$$\n",
    "E[Y \\mid X_2 = x_2] = \\beta_1 E[X_1] + \\beta_2 x_2 + \\beta_{1,2} E[X_1] x_2 = \\beta_2 x_2\n",
    "$$\n",
    "\n",
    "#### Variance:\n",
    "$$\n",
    "\\text{Var}(Y \\mid X_2 = x_2) = \\text{Var}(\\beta_1 X_1 + \\beta_2 x_2 + \\beta_{1,2} X_1 x_2)\n",
    "$$\n",
    "\n",
    "Using properties of variance, we get:\n",
    "\n",
    "$$\n",
    "\\text{Var}(Y \\mid X_2 = x_2) = \\beta_1^2 \\text{Var}(X_1) + \\beta_{1,2}^2 x_2^2 \\text{Var}(X_1) + \\sigma^2\n",
    "$$\n",
    "\n",
    "Again, the $\\sigma^2$ term comes from the fact that $X_2$ and $X_1$ are not independent, so we need to add the covariance term.\n",
    "\n",
    "Given $\\text{Var}(X_1) = \\sigma_1^2$, we have:\n",
    "\n",
    "$$\n",
    "\\text{Var}(Y \\mid X_2 = x_2) = \\beta_1^2 \\sigma_1^2 + \\beta_{1,2}^2 x_2^2 \\sigma_1^2 + \\sigma^2\n",
    "$$\n",
    "\n",
    "Thus, the conditional distribution $Y \\mid X_2$ is:\n",
    "$$\n",
    "Y \\mid X_2 \\sim N(\\beta_2 x_2, \\beta_1^2 \\sigma_1^2 + \\beta_{1,2}^2 x_2^2 \\sigma_1^2 + \\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "When does the probability model stated in the problem define regression models for $Y$ vs. $X_i, i = 1, 2$? That is, if we ignore one of the predictor variables do obtain a single predictor linear regression model for the other?\n",
    "\n",
    "### Solution\n",
    "For the probability model to define regression models for $Y$ vs. $X_i$, $i = 1, 2$, when ignoring one of the predictor variables to obtain a single predictor linear regression model for the other, the regression model should have the form:\n",
    "\n",
    "$$\n",
    "Y = \\alpha + \\beta_i X_i + \\epsilon\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha$ is the intercept.\n",
    "- $\\beta_i$ is the slope for the predictor$X_i$.\n",
    "- $\\epsilon$ is the random error term.\n",
    "\n",
    "Given the provided model, when we condition on $X_1$, the model becomes:\n",
    "\n",
    "$$\n",
    "Y = \\beta_1 X_1 + \\beta_2 X_2 + \\beta_{1,2} X_1 X_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "For this to be a simple linear regression model in $X_2$, the term involving the product $X_1 X_2$ (i.e., the interaction term) should not be present. This means $\\beta_{1,2} = 0$.\n",
    "\n",
    "Similarly, when we condition on $X_2$, the model becomes:\n",
    "\n",
    "$$\n",
    "Y = \\beta_1 X_1 + \\beta_2 X_2 + \\beta_{1,2} X_1 X_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "For this to be a simple linear regression model in$X_1$, again, the term involving the product $X_1 X_2$ should not be present. Again, this requires $\\beta_{1,2} = 0$.\n",
    "\n",
    "Thus, the probability model defines regression models for $Y$ vs.$X_i$,$i = 1, 2$, when the interaction term coefficient $\\beta_{1,2}$ is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "(Predicting the residual plot based on interaction model): Suppose we have $200$ data points generated from the following model\n",
    "\n",
    "$$\n",
    "Y = 4 X_1 - 2 X_2 + 4 X_1 X_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "where $\\sigma = 0.2$, $X_1$ is continuous predictor which is uniformly distributed on $[-1, 1]$, and $X_2$ is a binary predictor (e.g. a Bernoulli random variable). You can assume $X_2 = 0$ for about half the data points. The goal of this problem is to build your intuition about residual plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "**Without actually fitting a regression**, describe in detail what the residual plot would look like if we fit this data to a linear regression model with NO interaction term. To do so, follow the following procedure:\n",
    "\n",
    "1. First, think about what the data looks like when $X_2 = 0$ and $X_2 = 1$ separately. In each case, sketch the regression line and make note of how much variation there is around these lines to get an idea of what the cloud of $(X_i , Y_i)$ points will look like.\n",
    "\n",
    "2. Now consider what the fitted regression line will be based on this picture. What is a very rough estimate of the slopes $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$?\n",
    "\n",
    "3. To get a sense for what the residuals look like, take the difference between the true model and this line.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "Confirm your answer with simulations.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "(Drug interactions): When treating microbial infections and cancer, combinations of drugs can\n",
    "perform better than individual drugs. However, it can be difficult to identify which combinations are optimal for the reason that identifying very “high order” interactions is difficult. In order to understand the best way to combine $M$ drugs, we construct a regression where $Y$ is the “effect” of the drug and $X_i$ is a Bernoulli random variable representing whether or not the $i^{th}$ drug is present or not. We want to consider the possibility:\n",
    "\n",
    "$$\n",
    "Y \\sum_{i = 1}^M \\beta_i X_i \\sum_{i = 1}^M (\\sum_{j > i}^M \\beta_{i, j} X_i X_j) + \\sum_{i = 1}^M(\\sum_{j > i}^M \\sum_{k > j}^M \\beta_{i, j} X_i X_j X_k) + X_1 X_2 \\cdots X_M + \\epsilon\n",
    "$$\n",
    "\n",
    "For examples, with $M = 3$, we would have:\n",
    "\n",
    "$$\n",
    "Y = \\beta_1 X_1 + \\beta_2 X_2 \\beta_3 X_3 + \\beta_{1,2} X_1 X_2 + \\beta_{1, 3} X_1 X_3 + \\beta_{2, 3} X_2 X_3 + \\beta_{1, 2, 3} X_1 X_2 X_3 + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Suppose $M = 3$ and\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ \\beta_{1,2} \\\\ \\beta_{1,3} \\\\ \\beta_{2,3} \\\\ \\beta_{1,2,3} \\end{bmatrix}  = \\begin{bmatrix} 1.2 \\\\ -0.8 \\\\ -0.11 \\\\ 3.48 \\\\ -2.62 \\\\ 1.03 \\\\ 1.66 \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "What is your interpretation of each coefficient?\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "What is the optimal treatment, meaning which combination of drugs 1, 2 and 3 should we use to maximize $Y$? There are different ways you can approach this. One way is to make a list of each $(X_1, X_2, X_3)$, compute $Y$ for each one and the find the index of the maximum $Y$ value (using a for loop or `argmax`).\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "Now additional suppose that $\\sigma^2 = 1$. By generating simulated $Y$ values with these parameters for different values of $N$, determine how many data points are needed to reliably find that all interactions coefficients have p-values below $0.05$.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "Perform the same experiment as in (c) but fit the data to a model with no interactions. What do you find? How does adding the interaction terms influence the p-values.\n",
    "\n",
    "### Solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

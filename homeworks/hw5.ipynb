{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M50 Homework 5\n",
    "\n",
    "## Alex Craig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "(A binary and normal predictor): Consider the linear regression model:\n",
    "\n",
    "$$\n",
    "Y \\mid (X_1, X_2)  \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2, \\sigma^2)\n",
    "$$\n",
    "\n",
    "where the predictors obey\n",
    "\n",
    "$$\n",
    "X_1 \\sim Bernoulli(q)\n",
    "$$\n",
    "\n",
    "$$\n",
    "X_2 \\mid X_1 \\sim N(b X_1, \\sigma_{2,1}^2)\n",
    "$$\n",
    "\n",
    "You can assume $\\beta_0 = 0$ for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Derive a formulas for $cov(X_1, X_2)$ and $var(X_2)$ in terms of the model parameters.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "Derive a formula for $cov(Y, X_1)$ in terms of $\\beta_1$, q, $\\beta_2$, and $b$.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "Explain how the formula you derived in part (b) is related to the equation for $cov(Y, X_1)$ in the single predictor regression model (page 4 on week 3 notes). In particular, for what parameter values do the two formulas coincide? Your conclusion will be a particular case of what we saw to be true more generally (see week 5 notes) concerning the relationship between $\\beta_1$ and the covariances in a regression model with two predictions.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "(Earnings data revisited): Consider the earnings data. This can be loaded with:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Earnings/data/earnings.csv\")\n",
    "```\n",
    "\n",
    "As in the previous exercise set, you will study the association between earnings and gender, but now using regression with multiple predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Perform a linear regression using `statsmodels` with gender and height as predictors.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "Provide interpretations for each regression coefficient (like we did in class for the test score example).\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "Which factor, height or gender is more important based on your analysis?\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "Based one the fitted model, predict the chance that someone who is not male and is 5.8ft earns more than a male who is the same height? To get a sense for the importance (or lack-thereof) of the height predictor, compare this to the chance that a male earns more than a non-male (regardless of height).\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "(Sample distribution): In the notebook from class, we wrote code to generate samples from the sample distribution of $(\\hat{\\beta}_1, \\hat{\\beta}_2)$ in the model:\n",
    "\n",
    "$$\n",
    "X_1 \\sim N(0, 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "X_2 \\mid X_1 \\sim N(b X_1, 1 - b^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y \\mid (X_1, X_2) \\sim N(\\beta_1 X_1 + B_2 X_2, \\sigma^2)\n",
    "$$\n",
    "\n",
    "Specifically, we had a function which takes $\\beta_1$, $\\beta_2$ and $\\beta_0$ as inputs and returns a dataframe where the columns are the samples of $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$ respectively. When we plotted the correlation coefficient as a function of $b$ values and estimates the correlation coefficient between $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$, it was a decreasing line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "What would happen if instead of plotting the correlation coefficient, we plotted $SE(\\hat{\\beta}_1)$ as a function of $b$? Would it increase? decrease? neither? Note that both $X_1$ and $X_2$ are standardized, so the distribution of $X_1$ values is not changed when we adjust $b$. In answering this question, you can either give a geometric intuition, or do a calculation. You should check your answer with simulations, but you still need to provide a detailed explanation.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "Is it possible to have large standard errors on all the $\\hat{\\beta}_i$ values (measured relative to the true values of course), but still have a large (meaning close to one) value of $R^2$? If so, for what parameter values does this happen? Run simulation(s) to support your answer.\n",
    "\n",
    "### Solution"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
